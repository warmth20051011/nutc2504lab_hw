import csv
import random
import time

from openai import OpenAI
from deepeval.models import DeepEvalBaseLLM
from deepeval.metrics import (
    FaithfulnessMetric,
    AnswerRelevancyMetric,
    ContextualRecallMetric,
    ContextualPrecisionMetric,
    ContextualRelevancyMetric
)
from deepeval.test_case import LLMTestCase


# ======================
# åŸºæœ¬è¨­å®š
# ======================
INPUT_CSV = "day6_HW_questions.csv"
OUTPUT_CSV = "day6_HW_results.csv"

SAMPLE_SIZE = 5          # â­ æ¯æ¬¡éš¨æ©ŸæŠ½å¹¾é¡Œ
SLEEP_BEFORE_LLM = 1     # â­ æ¯æ¬¡å• LLM å‰ä¼‘æ¯ç§’æ•¸
SLEEP_AFTER_LLM = 1      # â­ æ¯æ¬¡å•å®Œ LLM å¾Œä¼‘æ¯ç§’æ•¸


# ======================
# è‡ªè¨‚ Llama.cpp LLM
# ======================
class LlamaCppModel(DeepEvalBaseLLM):
    def __init__(
        self,
        base_url="https://ws-06.huannago.com/v1",
        model_name="google/gemma-3-27b-it"
    ):
        self.base_url = base_url
        self.model_name = model_name

    def load_model(self):
        return OpenAI(
            api_key="NoNeed",
            base_url=self.base_url
        )

    def generate(self, prompt: str) -> str:
        client = self.load_model()
        response = client.chat.completions.create(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1,
        )
        return response.choices[0].message.content

    async def a_generate(self, prompt: str) -> str:
        return self.generate(prompt)

    def get_model_name(self):
        return f"Llama.cpp ({self.model_name})"


# ======================
# åˆå§‹åŒ– LLM
# ======================
custom_llm = LlamaCppModel()


# ======================
# Metrics
# ======================
faithfulness = FaithfulnessMetric(model=custom_llm)
answer_rel = AnswerRelevancyMetric(model=custom_llm)
context_recall = ContextualRecallMetric(model=custom_llm)
context_precision = ContextualPrecisionMetric(model=custom_llm)
context_relevancy = ContextualRelevancyMetric(model=custom_llm)


# ======================
# é è¨­ Context
# ======================
DEFAULT_CONTEXT = [
    "è‡ªä¾†æ°´å…¬å¸ä¾ç…§åœ‹å®¶é£²ç”¨æ°´æ°´è³ªæ¨™æº–é€²è¡Œæ·¨æ°´èˆ‡æ¶ˆæ¯’è™•ç†ï¼Œä»¥ç¢ºä¿ä¾›æ°´å®‰å…¨èˆ‡å“è³ªã€‚",
    "è‡ªä¾†æ°´ç›¸é—œæ¥­å‹™åŒ…å«æ°´è²»å¸³å–®å¯„é€ã€ç¹³è²»æ–¹å¼ã€é›»å­å¸³å–®ç”³è«‹åŠç”¨æ°´å•é¡Œè«®è©¢ç­‰æœå‹™ã€‚",
    "è‹¥æ°‘çœ¾åœ¨ç”¨æ°´ã€æ°´è³ªæˆ–å¸³å–®æ–¹é¢é‡åˆ°ç–‘å•ï¼Œå¯æ´½è©¢è‡ªä¾†æ°´å…¬å¸å®¢æœæˆ–è‡³ç‡Ÿæ¥­æ‰€è¾¦ç†ã€‚"
]

# ======================
# è®€å– CSV & æŠ½æ¨£
# ======================
with open(INPUT_CSV, newline="", encoding="utf-8") as fin:
    rows = list(csv.DictReader(fin))

sampled_rows = random.sample(rows, min(SAMPLE_SIZE, len(rows)))

print("\nğŸ¯ æœ¬æ¬¡éš¨æ©ŸæŠ½åˆ°çš„é¡Œç›® IDï¼š")
print([row["q_id"] for row in sampled_rows])
print("=" * 80)


# ======================
# é–‹å§‹è©•ä¼°
# ======================
with open(OUTPUT_CSV, "w", newline="", encoding="utf-8") as fout:
    fieldnames = [
        "q_id",
        "questions",
        "answer",
        "Faithfulness",
        "Answer_Relevancy",
        "Contextual_Recall",
        "Contextual_Precision",
        "Contextual_Relevancy"
    ]
    writer = csv.DictWriter(fout, fieldnames=fieldnames)
    writer.writeheader()

    for idx, row in enumerate(sampled_rows, start=1):
        print(f"\nğŸŸ¦ ç¬¬ {idx} é¡Œé–‹å§‹")
        print("-" * 80)

        question = row["questions"]
        print("â“ Question:")
        print(question)

        # ---- å‘¼å« LLMï¼ˆæ…¢æ…¢ä¾†ï¼‰----
        print("\nâ³ ç­‰å¾… LLM å›ç­”ä¸­...")
        time.sleep(SLEEP_BEFORE_LLM)

        try:
            answer = custom_llm.generate(question)
        except Exception as e:
            print("âŒ LLM ç™¼ç”ŸéŒ¯èª¤ï¼Œè·³éæ­¤é¡Œ")
            print(e)
            answer = "LLM Error"

        time.sleep(SLEEP_AFTER_LLM)

        print("\nğŸ¤– LLM Answer:")
        print(answer)

        # ---- å»ºç«‹æ¸¬è©¦æ¡ˆä¾‹ ----
        test_case = LLMTestCase(
            input=question,
            actual_output=answer,
            expected_output=answer,
            retrieval_context=DEFAULT_CONTEXT
        )

        # ---- è©•ä¼° ----
        faithfulness.measure(test_case)
        answer_rel.measure(test_case)
        context_recall.measure(test_case)
        context_precision.measure(test_case)
        context_relevancy.measure(test_case)

        print("\nğŸ“Š Metric Scores:")
        print(f"Faithfulness           : {faithfulness.score:.3f}")
        print(f"Answer Relevancy       : {answer_rel.score:.3f}")
        print(f"Contextual Recall      : {context_recall.score:.3f}")
        print(f"Contextual Precision   : {context_precision.score:.3f}")
        print(f"Contextual Relevancy   : {context_relevancy.score:.3f}")

        # ---- å¯«å…¥ CSV ----
        writer.writerow({
            "q_id": row["q_id"],
            "questions": question,
            "answer": answer,
            "Faithfulness": round(faithfulness.score, 3),
            "Answer_Relevancy": round(answer_rel.score, 3),
            "Contextual_Recall": round(context_recall.score, 3),
            "Contextual_Precision": round(context_precision.score, 3),
            "Contextual_Relevancy": round(context_relevancy.score, 3),
        })

        print("-" * 80)
        print(f"ğŸŸ© ç¬¬ {idx} é¡Œå®Œæˆ")
        time.sleep(1)


print("\nâœ… å…¨éƒ¨è©•ä¼°å®Œæˆ")
print(f"ğŸ“„ çµæœè¼¸å‡ºè‡³ï¼š{OUTPUT_CSV}")

