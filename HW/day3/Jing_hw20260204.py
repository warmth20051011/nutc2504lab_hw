import time
import requests
from typing import TypedDict
from pathlib import Path


from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END


BASE = "https://3090api.huannago.com"
CREATE_URL = f"{BASE}/api/v1/subtitle/tasks"
AUTH = ("nutc2504", "nutc2504")

WAV_PATH = "./Podcast_EP14_30s.wav"

OUT_DIR = Path("./out")
OUT_DIR.mkdir(exist_ok=True)

llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="",
    model="google/gemma-3-27b-it",
    temperature=0
)


class MeetingState(TypedDict):
    audio_path: str
    transcript: str
    minutes: str
    summary: str
    final_report: str

def wait_download(url: str, max_tries=300):
    for _ in range(max_tries):
        r = requests.get(url, timeout=(5, 60), auth=AUTH)
        if r.status_code == 200:
            return r.text
        time.sleep(2)
    raise TimeoutError("ASR timeout")


def asr_node(state: MeetingState):
    print("\nğŸ§ [ASR] ä¸Šå‚³éŸ³æª”ï¼Œå»ºç«‹ä»»å‹™")
    with open(state["audio_path"], "rb") as f:
        r = requests.post(CREATE_URL, files={"audio": f}, auth=AUTH)
    r.raise_for_status()
    task_id = r.json()["id"]

    print(f"ğŸ†” [ASR] task_id = {task_id}")
    print("â³ [ASR] ç­‰å¾…è½‰éŒ„å®Œæˆ...")

    srt_url = f"{BASE}/api/v1/subtitle/tasks/{task_id}/subtitle?type=SRT"
    transcript = wait_download(srt_url)

    print("âœ… [ASR] å®Œæˆ")
    return {"transcript": transcript}


def minutes_node(state: MeetingState):
    print("\nğŸ“ [Minutes] æ•´ç†è©³ç´°é€å­—ç¨¿")
    minutes = llm.invoke(f"""
è«‹å°‡ä»¥ä¸‹é€å­—ç¨¿æ•´ç†æˆã€è©³ç´°é€å­—æœƒè­°ç´€éŒ„ã€‘ï¼š
- ä¾æ™‚é–“é †åº
- ä¿ç•™æ™‚é–“è»¸
- ä½¿ç”¨ Markdown è¡¨æ ¼

{state['transcript']}
""").content
    print("âœ… [Minutes] å®Œæˆ")
    return {"minutes": minutes}



def summary_node(state: MeetingState):
    print("\nğŸ“Œ [Summary] ç”¢å‡ºé‡é»æ‘˜è¦")
    summary = llm.invoke(f"""
è«‹å°‡ä»¥ä¸‹æœƒè­°å…§å®¹æ•´ç†æˆã€é‡é»æ‘˜è¦ã€‘ï¼š
- æœƒè­°ä¸»é¡Œ
- æ ¸å¿ƒé‡é»
- çµè«–
- Action Items

{state['transcript']}
""").content
    print("âœ… [Summary] å®Œæˆ")
    return {"summary": summary}


def join_node(state: MeetingState):
    return {}


def writer_node(state: MeetingState):
    print("\nğŸ§© [Writer] æ•´åˆæœ€çµ‚è¼¸å‡º")
    final = f"""
# ğŸ“‹ æ™ºæ…§æœƒè­°è¨˜éŒ„

## ä¸€ã€é‡é»æ‘˜è¦
{state['summary']}

---

## äºŒã€è©³ç´°é€å­—æœƒè­°ç´€éŒ„
{state['minutes']}
"""
    return {"final_report": final}



graph = StateGraph(MeetingState)

graph.add_node("asr", asr_node)
graph.add_node("minutes_taker", minutes_node)
graph.add_node("summarizer", summary_node)
graph.add_node("join", join_node)
graph.add_node("writer", writer_node)

graph.set_entry_point("asr")

graph.add_edge("asr", "minutes_taker")
graph.add_edge("asr", "summarizer")
graph.add_edge("minutes_taker", "join")
graph.add_edge("summarizer", "join")
graph.add_edge("join", "writer")
graph.add_edge("writer", END)

app = graph.compile()



print("\nğŸ“Š LangGraph çµæ§‹ï¼š")
try:
    print(app.get_graph().draw_ascii())
except ImportError:
    print("""
        __start__
            |
           asr
          /   \\
 minutes_taker  summarizer
          \\   /
          writer
            |
          __end__
    """)




result = app.invoke({
    "audio_path": WAV_PATH,
    "transcript": "",
    "minutes": "",
    "summary": "",
    "final_report": ""
})

(Path("./out/transcript.srt")).write_text(result["transcript"], encoding="utf-8")
(Path("./out/minutes.md")).write_text(result["minutes"], encoding="utf-8")
(Path("./out/summary.md")).write_text(result["summary"], encoding="utf-8")
(Path("./out/final_report.md")).write_text(result["final_report"], encoding="utf-8")



print("\nğŸ‰ ä»»å‹™å®Œæˆï¼è¼¸å‡ºå¦‚ä¸‹ï¼š\n")

print("=====ã€é‡é»æ‘˜è¦ã€‘=====\n")
print(result["summary"])

print("\n=====ã€è©³ç´°é€å­—ç¨¿ï¼ˆå®Œæ•´ï¼‰ã€‘=====\n")
print(result["transcript"])

