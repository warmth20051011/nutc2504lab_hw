import time
import requests
from pathlib import Path
from typing import TypedDict

from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END


# ================== åŸºæœ¬è¨­å®š ==================
BASE = "https://3090api.huannago.com"
CREATE_URL = f"{BASE}/api/v1/subtitle/tasks"
AUTH = ("nutc2504", "nutc2504")

AUDIO_PATH = "./Podcast_EP14_30s.wav"

OUT_DIR = Path("./out")
OUT_DIR.mkdir(exist_ok=True)

llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="",
    model="google/gemma-3-27b-it",
    temperature=0
)


# ================== State ==================
class MeetingState(TypedDict):
    srt: str
    timeline: str
    summary: str
    final: str


# ================== ASR å·¥å…· ==================
def wait_download(url: str, max_tries=600):
    for _ in range(max_tries):
        try:
            r = requests.get(url, timeout=(5, 60), auth=AUTH)
            if r.status_code == 200:
                return r.text
        except requests.exceptions.ReadTimeout:
            pass
        time.sleep(2)
    raise TimeoutError("ASR timeout")


# ================== Node 1ï¼šASR ==================
def asr_node(state: MeetingState):
    print("\nğŸ§ [ASR] ä¸Šå‚³éŸ³æª”")

    with open(AUDIO_PATH, "rb") as f:
        r = requests.post(CREATE_URL, files={"audio": f}, auth=AUTH)
    r.raise_for_status()

    task_id = r.json()["id"]
    print(f"ğŸ†” task_id = {task_id}")

    srt_url = f"{BASE}/api/v1/subtitle/tasks/{task_id}/subtitle?type=SRT"
    srt_text = wait_download(srt_url)

    return {"srt": srt_text}


# ================== Node 2ï¼šTimeline ==================
def timeline_node(state: MeetingState):
    print("\nğŸ•’ [Timeline] ç”¢ç”Ÿå«æ™‚é–“è»¸é€å­—ç¨¿")

    prompt = f"""
è«‹å°‡ä»¥ä¸‹ SRT å…§å®¹æ•´ç†æˆã€æ™‚é–“è»¸é€å­—ç¨¿ã€‘ï¼š
- ä¿ç•™æ‰€æœ‰æ™‚é–“ç¢¼
- ä¸è¦æ‘˜è¦
- ç´”æ–‡å­—ã€ä¾æ™‚é–“é †åº

{state['srt']}
"""

    timeline = llm.invoke(prompt).content
    return {"timeline": timeline}


# ================== Node 3ï¼šSummary ==================
def summary_node(state: MeetingState):
    print("\nğŸ“Œ [Summary] ç”¢ç”Ÿé‡é»æ‘˜è¦")

    prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹å…§å®¹ç”¢ç”Ÿã€é‡é»æ‘˜è¦ã€‘ï¼š
- ä¸»é¡Œ
- æ ¸å¿ƒé‡é»ï¼ˆæ¢åˆ—ï¼‰
- çµè«–

{state['srt']}
"""

    summary = llm.invoke(prompt).content
    return {"summary": summary}


# ================== Node 4ï¼šWriter ==================
def writer_node(state: MeetingState):
    print("\nğŸ§© [Writer] è¼¸å‡ºçµæœ")

    timeline_path = OUT_DIR / "timeline.txt"
    summary_path = OUT_DIR / "summary.txt"

    timeline_path.write_text(state["timeline"], encoding="utf-8")
    summary_path.write_text(state["summary"], encoding="utf-8")

    print("\n=====ã€é‡é»æ‘˜è¦ã€‘=====\n")
    print(state["summary"])

    print("\n=====ã€è©³ç´°é€å­—ç¨¿ï¼ˆå«æ™‚é–“è»¸ï¼‰ã€‘=====\n")
    print(state["timeline"])

    print(f"\nâœ… å·²è¼¸å‡ºæª”æ¡ˆï¼š")
    print(f" - {timeline_path}")
    print(f" - {summary_path}")

    return {"final": "done"}

# ================== LangGraph ==================
graph = StateGraph(MeetingState)

graph.add_node("asr", asr_node)
graph.add_node("timeline", timeline_node)
graph.add_node("summary", summary_node)
graph.add_node("writer", writer_node)

graph.set_entry_point("asr")

# ğŸ‘‡ é—œéµçµæ§‹ï¼ˆè·Ÿåœ–ç‰‡ä¸€æ¨£ï¼‰
graph.add_edge("asr", "timeline")
graph.add_edge("asr", "summary")
graph.add_edge("timeline", "writer")
graph.add_edge("summary", "writer")
graph.add_edge("writer", END)

app = graph.compile()


# ================== Graph çµæ§‹é¡¯ç¤º ==================
print("\nğŸ“ LangGraph çµæ§‹ï¼š")
try:
    print(app.get_graph().draw_ascii())
except ImportError:
    print("""
        __start__
            |
           asr
          /   \\
     timeline summary
          \\   /
          writer
            |
          __end__
    """)


# ================== åŸ·è¡Œ ==================
result = app.invoke({
    "srt": "",
    "timeline": "",
    "summary": "",
    "final": ""
})

print("\nğŸ‰ ä»»å‹™å®Œæˆ")

