import requests
import time
import base64

from typing import TypedDict, Optional

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from playwright.sync_api import sync_playwright

from langgraph.graph import StateGraph, END

SEARXNG_URL = "https://puli-8080.huannago.com/search"


def search_searxng(query: str, time_range: str = None, limit: int = 1):
    print(f"ğŸ” æ­£åœ¨æœå°‹: {query}")

    params = {
        "q": query,
        "format": "json",
        "language": "zh-TW"
    }

    if time_range:
        params["time_range"] = time_range

    try:
        res = requests.get(SEARXNG_URL, params=params, timeout=10)
        res.raise_for_status()
        data = res.json()
        return [r for r in data.get("results", []) if "url" in r][:limit]
    except Exception as e:
        print("âŒ æœå°‹å¤±æ•—:", e)
        return []

SEARXNG_URL = "https://puli-8080.huannago.com/search"


llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="",
    model="google/gemma-3-27b-it",
    temperature=0
)

class QAState(TypedDict):
    question: str
    query: Optional[str]
    url: Optional[str]
    title: Optional[str]
    answer: Optional[str]
    
    
def check_cache(state: QAState) -> str:
    return "planner"


def planner(state: QAState) -> str:
    return "query_gen"
    
def query_gen(state: QAState) -> QAState:
    print("âœï¸ query_genï¼šç”¢ç”Ÿæœå°‹é—œéµå­—")
    return {
        **state,
        "query": state["question"]
    }
    
def search_tool(state: QAState) -> QAState:
    print("ğŸ” search_toolï¼šå‘¼å« SearXNG")

    results = search_searxng(state["query"], time_range="day", limit=1)
    if not results:
        return {**state, "answer": "æ‰¾ä¸åˆ°æœå°‹çµæœ"}

    first = results[0]
    return {
        **state,
        "url": first["url"],
        "title": first.get("title", "æœå°‹çµæœ")
    }
    
def vlm_read_website(url: str, title: str) -> str:
    print(f"[VLM] å•Ÿå‹•è¦–è¦ºé–±è®€: {url}")

    screenshots = []

    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            context = browser.new_context(
                viewport={"width": 1280, "height": 1200}
            )

            context.route(
                "**/*",
                lambda route, req: route.abort()
                if req.resource_type in ["image", "font", "stylesheet", "media"]
                else route.continue_()
            )

            page = context.new_page()
            page.goto(url, wait_until="domcontentloaded", timeout=30000)
            page.wait_for_timeout(1500)

            for i in range(1):
                scroll_y = i * 1000
                page.evaluate(f"window.scrollTo(0, {scroll_y})")
                page.wait_for_timeout(1500)

                img = base64.b64encode(page.screenshot()).decode("utf-8")
                screenshots.append(img)
                print(f" - æˆªåœ– {i+1} å®Œæˆ (Scroll: {scroll_y})")

            browser.close()

    except Exception as e:
        return f"âŒ æˆªåœ–å¤±æ•—: {e}"

    print(f"[LLM] æ­£åœ¨åˆ†æ {len(screenshots)} å¼µåœ–ç‰‡...")

    msgs = [
        HumanMessage(content=[
            {"type": "text", "text": f"é€™æ˜¯ç¶²é æˆªåœ–ï¼Œè«‹æ•´ç†èˆ‡ã€Œ{title}ã€ç›¸é—œçš„é‡é»ã€‚"},
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{screenshots[0]}"}}
        ])
    ]

    return llm.invoke(msgs).content



def final_answer(state: QAState) -> QAState:
    print("ğŸ“ final_answerï¼šVLM é–±è®€ç¶²é ")

    if not state.get("url"):
        return state

    answer = vlm_read_website(state["url"], state["title"])
    return {**state, "answer": answer}


workflow = StateGraph(QAState)

workflow.add_node("check_cache", lambda s: s)
workflow.add_node("query_gen", query_gen)
workflow.add_node("search_tool", search_tool)
workflow.add_node("final_answer", final_answer)

workflow.set_entry_point("check_cache")

workflow.add_conditional_edges(
    "check_cache",
    check_cache,
    {
        "planner": "query_gen",
    }
)

workflow.add_conditional_edges(
    "query_gen",
    planner,
    {
        "query_gen": "search_tool",
    }
)

workflow.add_edge("search_tool", "final_answer")
workflow.add_edge("final_answer", END)

app = workflow.compile()
print(app.get_graph().draw_ascii())

if __name__ == "__main__":
    question = input("è«‹è¼¸å…¥è¦æŸ¥è©¢çš„å•é¡Œï¼š")

    result = app.invoke({
        "question": question,
        "query": None,
        "url": None,
        "title": None,
        "answer": None
    })

    print("\n" + "=" * 40)
    print("ğŸ“Œ æœ€çµ‚å›ç­”ï¼š")
    print(result.get("answer"))


