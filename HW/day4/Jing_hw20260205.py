import requests
import json
import time
import os
import base64

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from playwright.sync_api import sync_playwright


SEARXNG_URL = "https://puli-8080.huannago.com/search"


def search_searxng(query: str, time_range: str = None, limit: int = 3):
    print(f"ğŸ” æ­£åœ¨æœå°‹: {query} (ç¯„åœ: {time_range if time_range else 'å…¨éƒ¨'})")

    params = {
        "q": query,
        "format": "json",
        "language": "zh-TW"
    }

    if time_range and time_range != "all":
        params["time_range"] = time_range

    try:
        response = requests.get(SEARXNG_URL, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        results = data.get("results", [])
        return [r for r in results if "url" in r][:limit]

    except Exception as e:
        print(f"âŒ æœå°‹å¤±æ•—: {e}")
        return []


llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="",
    model="google/gemma-3-27b-it",
    temperature=0
)


def vlm_read_website(url: str, title: str = "ç¶²é å…§å®¹") -> str:
    print(f"[VLM] å•Ÿå‹•è¦–è¦ºé–±è®€: {url}")

    screenshots = []

    try:
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            context = browser.new_context(
                viewport={"width": 1280, "height": 1200}
            )

            context.route(
                "**/*",
                lambda route, req: route.abort()
                if req.resource_type in ["image", "font", "stylesheet", "media"]
                else route.continue_()
            )

            page = context.new_page()
            page.goto(url, wait_until="domcontentloaded", timeout=30000)
            page.wait_for_timeout(1500)

            for i in range(1):
                scroll_y = i * 1000
                page.evaluate(f"window.scrollTo(0, {scroll_y})")
                page.wait_for_timeout(1500)

                img = base64.b64encode(page.screenshot()).decode("utf-8")
                screenshots.append(img)

                print(f" - æˆªåœ– {i+1} å®Œæˆ (Scroll: {scroll_y})")

            browser.close()

    except Exception as e:
        return f"âŒ æˆªåœ–å¤±æ•—: {e}"


    print(f"[LLM] æ­£åœ¨åˆ†æ {len(screenshots)} å¼µåœ–ç‰‡...")

    per_image_results = []


    for idx, img in enumerate(screenshots):
        msg = [
            HumanMessage(content=[
                {
                    "type": "text",
                    "text": f"é€™æ˜¯ä¸€å¼µç¶²é æˆªåœ–ï¼Œè«‹æ“·å–èˆ‡ã€Œ{title}ã€ç›¸é—œçš„é‡é»è³‡è¨Šã€‚"
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{img}"
                    }
                }
            ])
        ]

        try:
            result = llm.invoke(msg).content
            per_image_results.append(result)
        except Exception as e:
            per_image_results.append(f"åˆ†æå¤±æ•—: {e}")

    summary_msg = [
        HumanMessage(content=f"""
è«‹æ ¹æ“šä»¥ä¸‹å¤šå¼µç¶²é æˆªåœ–çš„åˆ†æå…§å®¹ï¼Œæ•´ç†ä¸€ä»½å®Œæ•´çš„é‡é»æ‘˜è¦ï¼š

{chr(10).join(per_image_results)}
""")
    ]

    try:
        return llm.invoke(summary_msg).content
    except Exception as e:
        return f"å½™æ•´å¤±æ•—: {e}"


if __name__ == "__main__":
    question = input("è«‹è¼¸å…¥è¦æŸ¥è©¢çš„å•é¡Œï¼š")

    start_time = time.time()

    results = search_searxng(question, time_range="day", limit=1)
    if not results:
        print("æ‰¾ä¸åˆ°æœå°‹çµæœ")
        exit()

    first = results[0]
    url = first["url"]
    title = first.get("title", "æœå°‹çµæœ")

    print("âœï¸ query_genï¼šç”¢ç”Ÿæœå°‹é—œéµå­—")
    print("ğŸ” search_toolï¼šå‘¼å« SearXNG")
    print("ğŸ“ final_answerï¼šVLM é–±è®€ç¶²é ")

    answer = vlm_read_website(url, title)

    print("\n" + "=" * 40)
    print("ğŸ“Œ æœ€çµ‚å›ç­”ï¼š")
    print(answer)
    print(f"\nâ±ï¸ ç¸½è€—æ™‚ï¼š{time.time() - start_time:.2f} ç§’")

